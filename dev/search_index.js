var documenterSearchIndex = {"docs":
[{"location":"10-tutorial/#Tutorial-and-Usage","page":"Tutorial","title":"Tutorial & Usage","text":"","category":"section"},{"location":"10-tutorial/#Overview","page":"Tutorial","title":"Overview","text":"This package provides both a high-level dct/idct interface and a performance-oriented plan-based interface.","category":"section"},{"location":"10-tutorial/#Quick-Start","page":"Tutorial","title":"Quick Start","text":"using AcceleratedDCTs\nusing FFTW # Required for CPU\n\nx = rand(100)\ny = dct(x)\nx_rec = idct(y)","category":"section"},{"location":"10-tutorial/#Plan-Based-API-(Recommended)","page":"Tutorial","title":"Plan-Based API (Recommended)","text":"To maximize performance, especially for repeated transforms, we separate resource allocation (cheap on CPU, expensive on GPU) from execution.","category":"section"},{"location":"10-tutorial/#1.-Plan-Creation","page":"Tutorial","title":"1. Plan Creation","text":"","category":"section"},{"location":"10-tutorial/#plan_dct(x::AbstractArray,-region1:ndims(x))","page":"Tutorial","title":"plan_dct(x::AbstractArray, region=1:ndims(x))","text":"Creates an optimized DCT-II plan.\n\nx: Input array (CPU Array or CuArray).\nReturns: DCTPlan.","category":"section"},{"location":"10-tutorial/#plan_idct(x::AbstractArray,-region1:ndims(x))","page":"Tutorial","title":"plan_idct(x::AbstractArray, region=1:ndims(x))","text":"Creates an optimized IDCT-III plan.\n\nReturns: IDCTPlan.","category":"section"},{"location":"10-tutorial/#2.-Execution","page":"Tutorial","title":"2. Execution","text":"","category":"section"},{"location":"10-tutorial/#Out-of-place:-*(plan,-x)","page":"Tutorial","title":"Out-of-place: *(plan, x)","text":"Computes the transform, allocating a new output array.\n\nusing AcceleratedDCTs: plan_dct\np = plan_dct(x)\ny = p * x","category":"section"},{"location":"10-tutorial/#In-place:-mul!(y,-plan,-x)","page":"Tutorial","title":"In-place: mul!(y, plan, x)","text":"Computes the transform in-place (updates y), utilizing pre-allocated plan buffers. Zero allocation.\n\nusing LinearAlgebra: mul!\nmul!(y, p, x)","category":"section"},{"location":"10-tutorial/#Inverse:-\\(plan,-y)","page":"Tutorial","title":"Inverse: \\(plan, y)","text":"Computes the inverse transform (IDCT) using the cached inverse plan.\n\nx_rec = p \\ y","category":"section"},{"location":"10-tutorial/#3.-Convenience-Functions","page":"Tutorial","title":"3. Convenience Functions","text":"dct(x)\nidct(x)\n\nNote: These functions create a new plan every call. Use plan_dct for loops.","category":"section"},{"location":"40-benchmarks/#Benchmarks","page":"Benchmarks","title":"Benchmarks","text":"Measurement of 3D DCT performance on varying grid sizes (N^3). Results collected using in-place mul! (where supported) to exclude allocation overhead. Lower is better.","category":"section"},{"location":"40-benchmarks/#GPU-Performance-(NVIDIA-RTX-2080-Ti)","page":"Benchmarks","title":"GPU Performance (NVIDIA RTX 2080 Ti)","text":"Grid Size (N^3) cuFFT (Baseline) Opt 3D DCT Batched DCT (Old)\n16^3 0.068 ms 0.104 ms 0.883 ms\n32^3 0.064 ms 0.117 ms 0.908 ms\n64^3 0.112 ms 0.237 ms 1.138 ms\n128^3 0.818 ms 1.414 ms 3.228 ms\n256^3 5.980 ms 10.455 ms 23.120 ms\n\nNote: Opt 3D DCT maintains excellent performance across all sizes, being only ~1.75x slower than raw cuFFT (due to necessary pre/post-processing). In contrast, the naive Batched DCT is ~3.9x slower than FFT. For N=256, Opt 3D DCT is >2.2x faster than the batched implementation.","category":"section"},{"location":"40-benchmarks/#CPU-Performance-(Intel-Xeon-Gold-6132)","page":"Benchmarks","title":"CPU Performance (Intel Xeon Gold 6132)","text":"","category":"section"},{"location":"40-benchmarks/#Single-Thread","page":"Benchmarks","title":"Single Thread","text":"Grid Size (N^3) FFTW rfft Opt 3D DCT FFTW dct Batched DCT\n16^3 0.010 ms 0.101 ms 0.055 ms 0.123 ms\n32^3 0.106 ms 0.815 ms 0.400 ms 0.880 ms\n64^3 1.203 ms 7.035 ms 4.299 ms 14.845 ms\n128^3 15.532 ms 63.666 ms 48.774 ms 146.376 ms\n256^3 254.233 ms 656.963 ms 425.112 ms 1580.613 ms","category":"section"},{"location":"40-benchmarks/#8-Threads","page":"Benchmarks","title":"8 Threads","text":"Grid Size (N^3) FFTW rfft Opt 3D DCT FFTW dct Batched DCT\n16^3 0.015 ms 0.150 ms 0.058 ms 0.424 ms\n32^3 0.100 ms 0.508 ms 0.426 ms 0.693 ms\n64^3 1.241 ms 3.856 ms 4.336 ms 8.703 ms\n128^3 14.905 ms 38.795 ms 47.904 ms 96.860 ms\n256^3 243.146 ms 332.595 ms 420.537 ms 1066.093 ms\n\nNote: On multi-threaded CPU, Opt 3D DCT (332ms) outperforms FFTW.dct (420ms) at large sizes (N=256) by being ~1.26x faster! It is consistently ~3x faster than the batched implementation. Single-threaded performance is slightly slower than FFTW.dct, highlighting efficient parallel scaling.","category":"section"},{"location":"50-troubleshooting/#Troubleshooting-/-Q-and-A","page":"Troubleshooting","title":"Troubleshooting / Q&A","text":"","category":"section"},{"location":"50-troubleshooting/#Q:-Why-do-I-get-StackOverflowError-when-running-on-CPU?","page":"Troubleshooting","title":"Q: Why do I get StackOverflowError when running on CPU?","text":"A: This typically happens if you are using standard Array (CPU) inputs but haven't loaded an FFT backend. AcceleratedDCTs.jl relies on AbstractFFTs.jl to dispatch to the correct FFT implementation. For CPU arrays, you must load FFTW.jl.\n\nSolution: Add using FFTW to your script or project.\n\nusing AcceleratedDCTs\nusing FFTW  # Required for CPU FFTs\n\nx = rand(1024)\ny = dct(x)  # Works!\n\nWithout FFTW, plan_rfft (used internally) fails to find a specific implementation and may fall back to generic methods that cause infinite recursion.","category":"section"},{"location":"20-theory/#Theory-and-Algorithms","page":"Theory","title":"Theory & Algorithms","text":"","category":"section"},{"location":"20-theory/#The-General-Idea-(Makhoul's-Algorithm)","page":"Theory","title":"The General Idea (Makhoul's Algorithm)","text":"See https://arxiv.org/abs/2110.01172 for detailed algorithms for 1D & 2D DCTs.\nCUDA C implementation: https://github.com/JeremieMelo/dct_cuda\n\nA standard DCT-II of length N can be computed by:\n\nPreprocessing: Permuting the input sequence x into a new sequence x.\nx takes even indices 0 2 4 from the front.\nx takes odd indices 1 3 5 from the back (reversed).\nFFT: Computing the Real FFT of x.\nPostprocessing: Applying complex weights (twiddle factors) to the FFT output to recover DCT coefficients.\n\nThis approach is faster than O(N^2) direct matrix multiplication and often faster than other O(N log N) approaches because highly optimized FFT libraries (FFTW, cuFFT) can be leveraged.","category":"section"},{"location":"20-theory/#Algorithm-2-(2D)","page":"Theory","title":"Algorithm 2 (2D)","text":"For a 2D N_1 times N_2 grid, we apply the permutation logic independently to both rows and columns.\n\nInput: x(n_1 n_2)\nPermutation: x(n_1 n_2) = x(tau(n_1) tau(n_2))\nTransform: X = textRFFT(x) (2D Real FFT)\nReconstruction: y(n_1 n_2) = 2 operatornameRe(dots) involving sums of 4 symmetric points from X.","category":"section"},{"location":"20-theory/#Algorithm-3-(3D)","page":"Theory","title":"Algorithm 3 (3D)","text":"We extend this to 3D.\n\nSeparable Permutation: x(n_1 n_2 n_3) = x(tau(n_1) tau(n_2) tau(n_3)).\nThis scatters the spatial correlation but allows us to use a single 3D FFT.\n3D RFFT: X = text3D_RFFT(x).\nRecursive Reconstruction:   The post-processing extracts the cosine components.\n\ny = 2 operatornameRe  W_3 cdot  W_2 cdot ( W_1 cdot X + dots ) + dots  \n\nThis is implemented efficiently in a single kernel pass in src/dct_optimized.jl.","category":"section"},{"location":"20-theory/#Major-Contribution","page":"Theory","title":"Major Contribution","text":"The major contribution of this package is the implementation of Algorithm 2 (2D) and Algorithm 3 (3D) in pure Julia in a device agnostic way, which reduce N-dimensional DCTs to N-dimensional Real-to-Complex (R2C) FFTs with O(N) pre/post-processing steps, avoiding the overhead of separable 1D transforms (which require redundant transposes). In particular, the 3D version is the first implementation of Algorithm 3 to the best of our knowledge.","category":"section"},{"location":"95-reference/#reference","page":"Reference","title":"Reference","text":"","category":"section"},{"location":"95-reference/#Contents","page":"Reference","title":"Contents","text":"Pages = [\"95-reference.md\"]","category":"section"},{"location":"95-reference/#Index","page":"Reference","title":"Index","text":"Pages = [\"95-reference.md\"]","category":"section"},{"location":"95-reference/#AcceleratedDCTs.DCTBatchedPlan","page":"Reference","title":"AcceleratedDCTs.DCTBatchedPlan","text":"DCTBatchedPlan{T, N}\n\nPrecomputed plan for N-dimensional DCT/IDCT operations (Batched).\n\nContains cached:\n\nFFT plans for each dimension\nTwiddle factors for each dimension\nWork buffers to avoid allocations\nTemp buffer for zero-allocation mul! operations\n\nUsage\n\nplan = plan_dct_batched(x)    # Create plan\ny = plan * x                  # Compute DCT\nmul!(y, plan, x)              # Compute DCT (zero allocation)\nx_rec = plan \\ y              # Compute IDCT\nldiv!(x, plan, y)             # Compute IDCT (zero allocation)\n\n\n\n\n\n","category":"type"},{"location":"95-reference/#AcceleratedDCTs.DCTPlan","page":"Reference","title":"AcceleratedDCTs.DCTPlan","text":"DCTPlan\n\nOptimized DCT Plan for device-agnostic execution.\n\n\n\n\n\n","category":"type"},{"location":"95-reference/#AcceleratedDCTs.IDCTPlan","page":"Reference","title":"AcceleratedDCTs.IDCTPlan","text":"IDCTPlan\n\nOptimized IDCT Plan for device-agnostic execution.\n\n\n\n\n\n","category":"type"},{"location":"95-reference/#AcceleratedDCTs.dct1d-Union{Tuple{AbstractVector{T}}, Tuple{T}} where T<:Real","page":"Reference","title":"AcceleratedDCTs.dct1d","text":"dct1d(x::AbstractVector{T}) where T<:Real\n\nCompute the 1D Discrete Cosine Transform (DCT-II) of a real vector.\n\nAlgorithm\n\nUses FFT-based computation:\n\nReorder input: v[n] = x[2n] for n < N/2, v[n] = x[2N-2n-1] for n >= N/2\nCompute FFT: V = fft(v)\nApply twiddle factors: y[k] = Re(V[k] * exp(-jÏ€k/(2N)))\n\nArguments\n\nx: Input vector of length N (must be even)\n\nReturns\n\nDCT coefficients vector of length N\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#AcceleratedDCTs.dct2d-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T<:Real","page":"Reference","title":"AcceleratedDCTs.dct2d","text":"dct2d(x::AbstractMatrix{T}) where T<:Real\n\nCompute the 2D Discrete Cosine Transform (DCT-II) of a real matrix.\n\nAlgorithm\n\nUses separable 1D DCT transforms:\n\nApply 1D DCT to each row\nApply 1D DCT to each column\n\nArguments\n\nx: Input matrix of size MÃ—N (M and N must be even)\n\nReturns\n\nDCT coefficients matrix of size MÃ—N\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#AcceleratedDCTs.dct3d-Union{Tuple{AbstractArray{T, 3}}, Tuple{T}} where T<:Real","page":"Reference","title":"AcceleratedDCTs.dct3d","text":"dct3d(x::AbstractArray{T,3}) where T<:Real\n\nCompute the 3D Discrete Cosine Transform (DCT-II) of a real 3D array.\n\nAlgorithm\n\nUses separable 1D DCT transforms:\n\nApply 1D DCT along dimension 1 (rows)\nApply 1D DCT along dimension 2 (columns)\nApply 1D DCT along dimension 3 (depth)\n\nArguments\n\nx: Input array of size LÃ—MÃ—N (all dimensions must be even)\n\nReturns\n\nDCT coefficients array of size LÃ—MÃ—N\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#AcceleratedDCTs.dct_batched!-Union{Tuple{T}, Tuple{AbstractVector{T}, AbstractVector{T}, AcceleratedDCTs.DCTBatchedPlan{T, 1}}} where T","page":"Reference","title":"AcceleratedDCTs.dct_batched!","text":"dct_batched!(y, x, plan::DCTBatchedPlan)\n\nCompute the N-dimensional DCT of x and store the result in y. Uses preallocated buffers from the plan.\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#AcceleratedDCTs.idct1d-Union{Tuple{AbstractVector{T}}, Tuple{T}} where T<:Real","page":"Reference","title":"AcceleratedDCTs.idct1d","text":"idct1d(y::AbstractVector{T}) where T<:Real\n\nCompute the 1D Inverse Discrete Cosine Transform (IDCT, DCT-III) of DCT coefficients.\n\nAlgorithm\n\nUses FFT-based computation:\n\nReconstruct FFT coefficients V from DCT coefficients y\nApply inverse FFT: v = ifft(V)\nInverse reorder to get original signal\n\nArguments\n\ny: DCT coefficients vector of length N (must be even)\n\nReturns\n\nReconstructed signal vector of length N\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#AcceleratedDCTs.idct2d-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T<:Real","page":"Reference","title":"AcceleratedDCTs.idct2d","text":"idct2d(y::AbstractMatrix{T}) where T<:Real\n\nCompute the 2D Inverse Discrete Cosine Transform (IDCT, DCT-III) of DCT coefficients.\n\nAlgorithm\n\nUses separable 1D IDCT transforms:\n\nApply 1D IDCT to each column\nApply 1D IDCT to each row\n\nArguments\n\ny: DCT coefficients matrix of size MÃ—N (M and N must be even)\n\nReturns\n\nReconstructed signal matrix of size MÃ—N\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#AcceleratedDCTs.idct3d-Union{Tuple{AbstractArray{T, 3}}, Tuple{T}} where T<:Real","page":"Reference","title":"AcceleratedDCTs.idct3d","text":"idct3d(y::AbstractArray{T,3}) where T<:Real\n\nCompute the 3D Inverse Discrete Cosine Transform (IDCT, DCT-III) of DCT coefficients.\n\nAlgorithm\n\nUses separable 1D IDCT transforms:\n\nApply 1D IDCT along dimension 3 (depth)\nApply 1D IDCT along dimension 2 (columns)\nApply 1D IDCT along dimension 1 (rows)\n\nArguments\n\ny: DCT coefficients array of size LÃ—MÃ—N (all dimensions must be even)\n\nReturns\n\nReconstructed signal array of size LÃ—MÃ—N\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#AcceleratedDCTs.idct_batched!-Union{Tuple{T}, Tuple{AbstractVector{T}, AbstractVector{T}, AcceleratedDCTs.DCTBatchedPlan{T, 1}}} where T","page":"Reference","title":"AcceleratedDCTs.idct_batched!","text":"idct_batched!(x, y, plan::DCTBatchedPlan)\n\nCompute the N-dimensional IDCT of y and store the result in x. Uses preallocated buffers from the plan.\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#AcceleratedDCTs.idct_postprocess_batch_dim1_kernel!-Tuple{Any}","page":"Reference","title":"AcceleratedDCTs.idct_postprocess_batch_dim1_kernel!","text":"IDCT Postprocess batch (inverse reorder). v: (N, Batch), x: (N, Batch)\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#AcceleratedDCTs.idct_preprocess_batch_dim1_kernel!-Tuple{Any}","page":"Reference","title":"AcceleratedDCTs.idct_preprocess_batch_dim1_kernel!","text":"IDCT Preprocess batch with precomputed twiddles. y: (N, Batch) real, V: (halfN+1, Batch) complex twiddles_inv: (halfN+1,) complex (cispi(k/(2N)))\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#AcceleratedDCTs.permutedims_2d!-Union{Tuple{T}, Tuple{AbstractMatrix{T}, AbstractMatrix{T}}} where T","page":"Reference","title":"AcceleratedDCTs.permutedims_2d!","text":"permutedims_2d!(dst, src)\n\nIn-place 2D transpose using KernelAbstractions.\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#AcceleratedDCTs.permutedims_2d_kernel!-Tuple{Any}","page":"Reference","title":"AcceleratedDCTs.permutedims_2d_kernel!","text":"2D permutedims! kernel\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#AcceleratedDCTs.permutedims_3d!-Union{Tuple{T}, Tuple{AbstractArray{T, 3}, AbstractArray{T, 3}, Tuple{Int64, Int64, Int64}}} where T","page":"Reference","title":"AcceleratedDCTs.permutedims_3d!","text":"permutedims_3d!(dst, src, perm)\n\nIn-place 3D permutedims using KernelAbstractions.  Zero allocation after initial kernel compilation.\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#AcceleratedDCTs.permutedims_3d_kernel!-Tuple{Any}","page":"Reference","title":"AcceleratedDCTs.permutedims_3d_kernel!","text":"3D permutedims! kernel: dst[i,j,k] = src[perm_inverse...] perm specifies the output dimension order from input dimensions.\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#AcceleratedDCTs.plan_dct_batched-Union{Tuple{AbstractArray{T, N}}, Tuple{N}, Tuple{T}} where {T<:Real, N}","page":"Reference","title":"AcceleratedDCTs.plan_dct_batched","text":"plan_dct_batched(x::AbstractArray{T, N}) where {T <: Real, N}\n\nCreate a batched DCT plan for arrays with the same size and element type as x.\n\nExample\n\nx = rand(256, 256, 256)\nplan = plan_dct_batched(x)\ny = plan * x   # DCT\nmul!(y, plan, x)  # DCT (zero allocation)\nx2 = plan \\ y  # IDCT\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#AcceleratedDCTs.postprocess_batch_dim1_kernel!-Tuple{Any}","page":"Reference","title":"AcceleratedDCTs.postprocess_batch_dim1_kernel!","text":"Postprocess batch of 1D signals with precomputed twiddles. V: (halfN+1, Batch) complex, y: (N, Batch) real twiddles: (N,) complex\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#AcceleratedDCTs.preprocess_batch_dim1_kernel!-Tuple{Any}","page":"Reference","title":"AcceleratedDCTs.preprocess_batch_dim1_kernel!","text":"Preprocess batch of 1D signals along first dimension. x: (N, Batch), v: (N, Batch)\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#Base.:*-Union{Tuple{T}, Tuple{AcceleratedDCTs.DCTBatchedPlan{T, 1}, AbstractVector{T}}} where T","page":"Reference","title":"Base.:*","text":"Base.:*(plan::DCTBatchedPlan, x::AbstractArray) -> y\n\nCompute the N-dimensional DCT of x using the precomputed plan.\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#Base.:\\-Union{Tuple{T}, Tuple{AcceleratedDCTs.DCTBatchedPlan{T, 1}, AbstractVector{T}}} where T","page":"Reference","title":"Base.:\\","text":"Base.:\\(plan::DCTBatchedPlan, y::AbstractArray) -> x\n\nCompute the N-dimensional IDCT of y using the precomputed plan.\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#LinearAlgebra.ldiv!-Union{Tuple{T}, Tuple{AbstractArray{T, 3}, AcceleratedDCTs.DCTBatchedPlan{T, 3}, AbstractArray{T, 3}}} where T","page":"Reference","title":"LinearAlgebra.ldiv!","text":"LinearAlgebra.ldiv!(x, plan::DCTBatchedPlan{T, 3}, y) -> x\n\nCompute 3D IDCT with zero allocation using ping-pong buffer strategy.\n\nFlow (reverse of DCT):\n\ny    â†’ perm(3,1,2) â†’ buf  # buf = (3',1',2')\nbuf  â†’ IDCT dim1 â†’ x     # x   = (3,1',2')\nx    â†’ perm(3,2,1) â†’ buf  # buf = (2',1',3)\nbuf  â†’ IDCT dim1 â†’ x     # x   = (2,1',3)\nx    â†’ perm(2,1,3) â†’ buf  # buf = (1',2,3)\nbuf  â†’ IDCT dim1 â†’ x     # x   = (1,2,3) âœ“\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#LinearAlgebra.mul!-Union{Tuple{T}, Tuple{AbstractArray{T, 3}, AcceleratedDCTs.DCTBatchedPlan{T, 3}, AbstractArray{T, 3}}} where T","page":"Reference","title":"LinearAlgebra.mul!","text":"LinearAlgebra.mul!(y, plan::DCTBatchedPlan{T, 3}, x) -> y\n\nCompute 3D DCT with zero allocation using ping-pong buffer strategy. Uses y and plan.temp_buffer alternately to avoid allocations.\n\nFlow (ping-pong between buf and y):\n\nx    â†’ DCT dim1 â†’ buf     # buf = (1',2,3)\nbuf  â†’ perm(2,1,3) â†’ y    # y   = (2,1',3)\ny    â†’ DCT dim1 â†’ buf     # buf = (2',1',3)\nbuf  â†’ perm(3,2,1) â†’ y    # y   = (3,2',1')\ny    â†’ DCT dim1 â†’ buf     # buf = (3',2',1')\nbuf  â†’ perm(2,3,1) â†’ y    # y   = (1',2',3') âœ“\n\n\n\n\n\n","category":"method"},{"location":"30-implementation/#Implementation-Details","page":"Implementation","title":"Implementation Details","text":"","category":"section"},{"location":"30-implementation/#KernelAbstractions.jl","page":"Implementation","title":"KernelAbstractions.jl","text":"The code is written using KernelAbstractions, meaning the exact same code runs on:\n\nCPU (using Base.Threads)\nNVIDIA GPU (using CUDA.jl)\nAMD GPU (using AMDGPU.jl) - conceptual support, untested\n\nWe strictly avoid \"scalar indexing\" (accessing single elements from the host), ensuring high performance on GPUs.","category":"section"},{"location":"30-implementation/#Plan-Based-API-(AbstractFFTs)","page":"Implementation","title":"Plan-Based API (AbstractFFTs)","text":"To maximize performance, we separate resource allocation (cheap on CPU, expensive on GPU) from execution.\n\nplan_dct(x):\nAllocates temporary buffers (tmp_real, tmp_comp).\nCreates an internal FFT plan (plan_rfft).\nPre-calculates twiddle factors (cispi(...)) on the device.\nmul!(y, p, x):\nReuses all buffers.\nZero memory allocation during execution.","category":"section"},{"location":"#AcceleratedDCTs.jl","page":"AcceleratedDCTs.jl","title":"AcceleratedDCTs.jl","text":"Documentation for AcceleratedDCTs.","category":"section"},{"location":"#Introduction","page":"AcceleratedDCTs.jl","title":"Introduction","text":"AcceleratedDCTs.jl aims to provide the fastest possible Discrete Cosine Transform (DCT) for Julia, running on both CPUs and GPUs. It focuses on the DCT-II (Standard \"DCT\") and DCT-III (Inverse DCT), commonly used in signal processing and solving partial differential equations (PDEs).\n\nThe core innovation of this package is the implementation of Algorithm 2 (2D) and Algorithm 3 (3D), which reduce N-dimensional DCTs to N-dimensional Real-to-Complex (R2C) FFTs with O(N) pre/post-processing steps, avoiding the overhead of separable 1D transforms (which require redundant transposes).","category":"section"},{"location":"#Key-Features","page":"AcceleratedDCTs.jl","title":"Key Features","text":"âš¡ High Performance: optimized algorithms (Makhoul's method) that outperform standard separable approaches on GPU (~2x speedup for 3D) and CPU (~3x speedup for 3D).\nðŸš€ Device Agnostic: Runs on CPU (Threads) and GPU (CuArray, ROCArray via KernelAbstractions).\nðŸ§© AbstractFFTs Compatible: Zero-allocation mul!, ldiv!, and precomputed Plan support.\nðŸ“¦ 3D Optimized: Specialized 3D kernels that avoid redundant transposes.","category":"section"}]
}
