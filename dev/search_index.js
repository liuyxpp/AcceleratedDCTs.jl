var documenterSearchIndex = {"docs":
[{"location":"10-tutorial/#Tutorial-and-Usage","page":"Tutorial","title":"Tutorial & Usage","text":"","category":"section"},{"location":"10-tutorial/#Getting-Started","page":"Tutorial","title":"Getting Started","text":"using AcceleratedDCTs\nusing FFTW  # Required for CPU execution\nusing CUDA  # Optional: for GPU execution\n\n# Create random data (1D, 2D, or 3D)\nx = rand(100) ","category":"section"},{"location":"10-tutorial/#High-Level-API-(Convenience)","page":"Tutorial","title":"High-Level API (Convenience)","text":"The simplest way to use the package. Note that these functions creating a new plan every call, which has some overhead.","category":"section"},{"location":"10-tutorial/#Standard-DCT-(DCT-II-/-DCT-III)","page":"Tutorial","title":"Standard DCT (DCT-II / DCT-III)","text":"Used for general signal processing and half-sample symmetric boundaries.\n\nusing AcceleratedDCTs: dct, idct\n\n# Forward (DCT-II)\ny = dct(x)\n\n# Inverse (DCT-III)\nx_rec = idct(y)","category":"section"},{"location":"10-tutorial/#Symmetric-DCT-(DCT-I-/-IDCT-I)","page":"Tutorial","title":"Symmetric DCT (DCT-I / IDCT-I)","text":"Used for whole-sample symmetric boundary conditions.\n\nusing AcceleratedDCTs: dct1, idct1\n\n# Forward (DCT-I)\ny = dct1(x)\n\n# Inverse (IDCT-I)\nx_rec = idct1(y)\n\n","category":"section"},{"location":"10-tutorial/#Performance-API-(Plan-Based)","page":"Tutorial","title":"Performance API (Plan-Based)","text":"For production code (e.g., inside loops), use the plan-based API to separate resource allocation from execution. This allows you to pre-allocate buffers and reuse them, achieving zero-allocation execution.","category":"section"},{"location":"10-tutorial/#1.-Create-a-Plan","page":"Tutorial","title":"1. Create a Plan","text":"Plans pre-calculate twiddle factors and allocate necessary temporary buffers.\n\nusing AcceleratedDCTs: plan_dct, plan_dct1\n\n# For Standard DCT-II/III\np = plan_dct(x)\n\n# For Symmetric DCT-I\np1 = plan_dct1(x)","category":"section"},{"location":"10-tutorial/#2.-Execute-the-Plan","page":"Tutorial","title":"2. Execute the Plan","text":"Once you have a plan, you can execute it in multiple ways.","category":"section"},{"location":"10-tutorial/#Out-of-Place-(Allocating)","page":"Tutorial","title":"Out-of-Place (Allocating)","text":"Creates a new output array.\n\ny = p * x","category":"section"},{"location":"10-tutorial/#In-Place-(Zero-Allocation)","page":"Tutorial","title":"In-Place (Zero Allocation)","text":"Writes result directly to y. Fastest method.\n\nusing LinearAlgebra: mul!\n\ny = similar(x)\nmul!(y, p, x)","category":"section"},{"location":"10-tutorial/#Inverse-Transform","page":"Tutorial","title":"Inverse Transform","text":"You can use the same plan to compute the inverse.\n\n# Allocating Inverse\nx_rec = p \\ y\n\n# Zero-Allocation Inverse (using ldiv!)\nusing LinearAlgebra: ldiv!\nldiv!(x_rec, p, y)\n\n# Explicit Inverse Plan\npinv = inv(p)\nmul!(x_rec, pinv, y)\n\n","category":"section"},{"location":"10-tutorial/#Advanced-Usage","page":"Tutorial","title":"Advanced Usage","text":"","category":"section"},{"location":"10-tutorial/#GPU-Support","page":"Tutorial","title":"GPU Support","text":"Simply pass a CuArray (or ROCArray) to the functions. The package automatically selects the appropriate GPU kernel.\n\nusing CUDA\nx_gpu = CUDA.rand(128, 128, 128)\np = plan_dct(x_gpu)\ny_gpu = p * x_gpu","category":"section"},{"location":"10-tutorial/#Precision-(Float32-vs-Float64)","page":"Tutorial","title":"Precision (Float32 vs Float64)","text":"The package supports any AbstractFloat type. For maximum performance on GPUs, use Float32.\n\nx_f32 = rand(Float32, 1024)\np = plan_dct(x_f32) # Creates a Float32 plan","category":"section"},{"location":"40-benchmarks/#Benchmarks","page":"Benchmarks","title":"Benchmarks","text":"Measurement of 3D DCT performance on varying grid sizes (N^3). Results collected using in-place mul! (where supported) to exclude allocation overhead. Lower is better.","category":"section"},{"location":"40-benchmarks/#GPU-Performance-(NVIDIA-RTX-2080-Ti)","page":"Benchmarks","title":"GPU Performance (NVIDIA RTX 2080 Ti)","text":"Grid Size (N^3) cuFFT (Baseline) Opt 3D DCT Batched DCT (Old)\n16^3 0.080 ms 0.113 ms 1.041 ms\n32^3 0.076 ms 0.131 ms 0.946 ms\n64^3 0.116 ms 0.246 ms 1.165 ms\n128^3 0.833 ms 1.423 ms 3.302 ms\n256^3 5.945 ms 10.417 ms 26.019 ms\n\nNote: Opt 3D DCT maintains excellent performance across all sizes, being only ~1.75x slower than raw cuFFT (due to necessary pre/post-processing). In contrast, the naive Batched DCT is ~3.9x slower than FFT. For N=256, Opt 3D DCT is >2.2x faster than the batched implementation.","category":"section"},{"location":"40-benchmarks/#CPU-Performance-(Intel-Xeon-Gold-6132)","page":"Benchmarks","title":"CPU Performance (Intel Xeon Gold 6132)","text":"","category":"section"},{"location":"40-benchmarks/#Single-Thread","page":"Benchmarks","title":"Single Thread","text":"Grid Size (N^3) FFTW rfft Opt 3D DCT FFTW dct Batched DCT\n16^3 0.010 ms 0.109 ms 0.046 ms 0.138 ms\n32^3 0.090 ms 0.791 ms 0.362 ms 0.813 ms\n64^3 1.193 ms 6.957 ms 4.319 ms 14.323 ms\n128^3 17.707 ms 63.965 ms 52.700 ms 142.195 ms\n256^3 241.730 ms 663.925 ms 422.634 ms 1596.978 ms","category":"section"},{"location":"40-benchmarks/#8-Threads","page":"Benchmarks","title":"8 Threads","text":"Grid Size (N^3) FFTW rfft Opt 3D DCT FFTW dct Batched DCT\n16^3 0.062 ms 0.196 ms 0.106 ms 0.460 ms\n32^3 0.122 ms 0.464 ms 0.280 ms 0.935 ms\n64^3 0.650 ms 2.413 ms 1.574 ms 7.997 ms\n128^3 4.278 ms 10.961 ms 14.438 ms 80.503 ms\n256^3 46.120 ms 108.365 ms 90.370 ms 842.106 ms\n\nNote: On multi-threaded CPU, Opt 3D DCT is highly competitive. At 128^3, it outperforms FFTW.dct (10.96 ms vs 14.44 ms). At 256^3, it is slightly slower but comparable (108 ms vs 90 ms). It is consistently >7x faster than the batched implementation at large sizes. Single-threaded performance remains slower due to the overhead of our pure-Julia plan construction and kernel dispatch versus FFTW's highly optimized planner.","category":"section"},{"location":"40-benchmarks/#DCT-I-Performance-(Symmetric-Boundary)","page":"Benchmarks","title":"DCT-I Performance (Symmetric Boundary)","text":"Measurement of 3D DCT-I performance on varying grid sizes (M^3). Note that for DCT-I, the internal FFT size is N = 2M-2.","category":"section"},{"location":"40-benchmarks/#GPU-Performance-(NVIDIA-RTX-2080-Ti)-2","page":"Benchmarks","title":"GPU Performance (NVIDIA RTX 2080 Ti)","text":"CUDA does not provide a native DCT-I. We compare against a raw cuFFT R2C transform of size (2M-2)^3 to show the overhead of our implementation (logic + kernels).\n\nGrid Size (M^3) cuFFT rfft (N=2M-2) Opt DCT-I Overhead\n16^3 0.079 ms 0.108 ms ~1.36x\n32^3 0.245 ms 0.313 ms ~1.27x\n64^3 1.204 ms 1.323 ms ~1.10x\n128^3 23.289 ms 23.951 ms ~1.03x\n256^3 88.519 ms 92.446 ms ~1.04x\n\nNote: Our optimized DCT-I implementation adds minimal overhead (<5% at large sizes) over the raw FFT, demonstrating extremely efficient kernel implementation.","category":"section"},{"location":"40-benchmarks/#CPU-Performance-(Intel-Xeon-Gold-6132)-2","page":"Benchmarks","title":"CPU Performance (Intel Xeon Gold 6132)","text":"Comparing against FFTW's native DCT-I (REDFT00).","category":"section"},{"location":"40-benchmarks/#Single-Thread-2","page":"Benchmarks","title":"Single Thread","text":"Grid Size (M^3) FFTW DCT-I Opt DCT-I FFTW rfft (N=2M-2)\n16^3 0.128 ms 0.417 ms 0.185 ms\n32^3 2.374 ms 8.528 ms 6.608 ms\n64^3 7.909 ms 35.659 ms 19.987 ms\n128^3 476.919 ms 806.853 ms 657.360 ms\n256^3 1022.623 ms 4601.621 ms 3596.196 ms","category":"section"},{"location":"40-benchmarks/#8-Threads-2","page":"Benchmarks","title":"8 Threads","text":"Grid Size (M^3) FFTW DCT-I Opt DCT-I FFTW rfft (N=2M-2)\n16^3 0.157 ms 0.490 ms 0.253 ms\n32^3 110.692 ms 1.495 ms 1.150 ms\n64^3 3.330 ms 5.790 ms 3.498 ms\n128^3 1839.493 ms 118.878 ms 99.294 ms\n256^3 140.238 ms 679.484 ms 529.750 ms\n\nNote: The above tables show performance of the original rfft-based DCT-I implementation. Since then, we have updated the CPU implementation to use FFTW's native REDFT00 directly via automatic dispatch, achieving identical performance to FFTW DCT-I. The GPU implementation continues to use the mirroring + FFT approach (no native DCT-I in cuFFT). Also note the abnormal performance at 128^3 for the FFTW DCT-I in the 8-thread benchmark.","category":"section"},{"location":"50-troubleshooting/#Troubleshooting-/-Q-and-A","page":"Troubleshooting","title":"Troubleshooting / Q&A","text":"","category":"section"},{"location":"50-troubleshooting/#Q:-Why-do-I-get-StackOverflowError-when-running-on-CPU?","page":"Troubleshooting","title":"Q: Why do I get StackOverflowError when running on CPU?","text":"A: This typically happens if you are using standard Array (CPU) inputs but haven't loaded an FFT backend. AcceleratedDCTs.jl relies on AbstractFFTs.jl to dispatch to the correct FFT implementation. For CPU arrays, you must load FFTW.jl.\n\nSolution: Add using FFTW to your script or project.\n\nusing AcceleratedDCTs\nusing FFTW  # Required for CPU FFTs\n\nx = rand(1024)\ny = dct(x)  # Works!\n\nWithout FFTW, plan_rfft (used internally) fails to find a specific implementation and may fall back to generic methods that cause infinite recursion.","category":"section"},{"location":"20-theory/#Theory-and-Algorithms","page":"Theory","title":"Theory & Algorithms","text":"This package provides fast, device-agnostic implementations of the following DCT variants for 1D, 2D, and 3D data:\n\nDCT-II (Forward) and DCT-III (Inverse): The most common DCT pair, used in signal processing, image compression (JPEG), and solving PDEs with half-sample symmetric boundary conditions.\nDCT-I and IDCT-I: DCT with whole-sample symmetric boundary conditions, useful for applications requiring symmetric extensions.","category":"section"},{"location":"20-theory/#DCT-II-/-DCT-III-Definitions","page":"Theory","title":"DCT-II / DCT-III Definitions","text":"Forward Transform (DCT-II)\n\nX_k = sum_n=0^N-1 x_n cosleft(fracpiNleft(n+frac12right)kright)\n\nInverse Transform (DCT-III)\n\nx_n = frac12X_0 + sum_k=1^N-1 X_k cosleft(fracpiNnleft(k+frac12right)right)","category":"section"},{"location":"20-theory/#DCT-I-Definition","page":"Theory","title":"DCT-I Definition","text":"DCT-I\n\nY_k = X_0 + (-1)^k X_M-1 + 2sum_j=1^M-2 X_j cosleft(fracpi j kM-1right)\n\nThe IDCT-I is computed as DCT-I(x) / (2M-2), making it self-inverse up to scaling.","category":"section"},{"location":"20-theory/#The-General-Idea-of-Implementation-(Makhoul's-Algorithm)","page":"Theory","title":"The General Idea of Implementation (Makhoul's Algorithm)","text":"A standard DCT-II of length N can be computed by:\n\nPreprocessing: Permuting the input sequence x into a new sequence x.\nx takes even indices 0 2 4 from the front.\nx takes odd indices 1 3 5 from the back (reversed).\nFFT: Computing the Real FFT of x.\nPostprocessing: Applying complex weights (twiddle factors) to the FFT output to recover DCT coefficients.\n\nThis approach is faster than O(N^2) direct matrix multiplication and often faster than other O(N log N) approaches because highly optimized FFT libraries (FFTW, cuFFT) can be leveraged.","category":"section"},{"location":"20-theory/#Algorithm-2-(2D)","page":"Theory","title":"Algorithm 2 (2D)","text":"For a 2D N_1 times N_2 grid, we apply the permutation logic independently to both rows and columns.\n\nInput: x(n_1 n_2)\nPermutation: x(n_1 n_2) = x(tau(n_1) tau(n_2))\nTransform: X = textRFFT(x) (2D Real FFT)\nReconstruction: y(n_1 n_2) = 2 operatornameRe(dots) involving sums of 4 symmetric points from X.","category":"section"},{"location":"20-theory/#Algorithm-3-(3D)","page":"Theory","title":"Algorithm 3 (3D)","text":"We extend this to 3D.\n\nSeparable Permutation: x(n_1 n_2 n_3) = x(tau(n_1) tau(n_2) tau(n_3)).\nThis scatters the spatial correlation but allows us to use a single 3D FFT.\n3D RFFT: X = text3D_RFFT(x).\nRecursive Reconstruction:   The post-processing extracts the cosine components.\n\ny = 2 operatornameRe  W_3 cdot  W_2 cdot ( W_1 cdot X + dots ) + dots  \n\nThis is implemented efficiently in a single kernel pass in src/dct_optimized.jl.","category":"section"},{"location":"20-theory/#Major-Contribution","page":"Theory","title":"Major Contribution","text":"The major contribution of this package is the implementation of Algorithm 2 (2D) and Algorithm 3 (3D) in pure Julia in a device agnostic way, which reduce N-dimensional DCTs to N-dimensional Real-to-Complex (R2C) FFTs with O(N) pre/post-processing steps, avoiding the overhead of separable 1D transforms (which require redundant transposes). In particular, the 3D version is the first implementation of Algorithm 3 to the best of our knowledge.","category":"section"},{"location":"20-theory/#DCT-I-Algorithm","page":"Theory","title":"DCT-I Algorithm","text":"The DCT-I is computed using a symmetric extension + FFT approach:\n\nMirroring: Extend the input X of length M into a symmetric sequence of length N = 2M-2:  g = X_0 X_1 ldots X_M-1 X_M-2 ldots X_1\nFFT: Compute the Real FFT of the mirrored sequence.\nExtraction: Take the real part of the first M FFT coefficients.\n\nThis approach leverages optimized R2C FFT libraries and is implemented in src/dct1_optimized.jl.","category":"section"},{"location":"20-theory/#References","page":"Theory","title":"References","text":"J. Makhoul, â€œA fast cosine transform in one and two dimensions,â€ IEEE Transactions on Acoustics, Speech, and Signal Processing, 1980.\nSee also https://arxiv.org/abs/2110.01172 for detailed algorithms for 1D & 2D DCTs.\nAnd their CUDA C implementation (1D & 2D): https://github.com/JeremieMelo/dct_cuda","category":"section"},{"location":"95-reference/#reference","page":"Reference","title":"Reference","text":"","category":"section"},{"location":"95-reference/#Contents","page":"Reference","title":"Contents","text":"Pages = [\"95-reference.md\"]","category":"section"},{"location":"95-reference/#Index","page":"Reference","title":"Index","text":"Pages = [\"95-reference.md\"]","category":"section"},{"location":"95-reference/#AcceleratedDCTs.DCT1Plan","page":"Reference","title":"AcceleratedDCTs.DCT1Plan","text":"DCT1Plan\n\nOptimized DCT-I Plan for device-agnostic execution.\n\n\n\n\n\n","category":"type"},{"location":"95-reference/#AcceleratedDCTs.DCTBatchedPlan","page":"Reference","title":"AcceleratedDCTs.DCTBatchedPlan","text":"DCTBatchedPlan{T, N}\n\nPrecomputed plan for N-dimensional DCT/IDCT operations (Batched).\n\nContains cached:\n\nFFT plans for each dimension\nTwiddle factors for each dimension\nWork buffers to avoid allocations\nTemp buffer for zero-allocation mul! operations\n\nUsage\n\nplan = plan_dct_batched(x)    # Create plan\ny = plan * x                  # Compute DCT\nmul!(y, plan, x)              # Compute DCT (zero allocation)\nx_rec = plan \\ y              # Compute IDCT\nldiv!(x, plan, y)             # Compute IDCT (zero allocation)\n\n\n\n\n\n","category":"type"},{"location":"95-reference/#AcceleratedDCTs.DCTPlan","page":"Reference","title":"AcceleratedDCTs.DCTPlan","text":"DCTPlan\n\nOptimized DCT Plan for device-agnostic execution.\n\n\n\n\n\n","category":"type"},{"location":"95-reference/#AcceleratedDCTs.FFTWBasedDCT1Plan","page":"Reference","title":"AcceleratedDCTs.FFTWBasedDCT1Plan","text":"FFTWBasedDCT1Plan\n\nDCT-I Plan for CPU arrays using FFTW's native REDFT00.\n\n\n\n\n\n","category":"type"},{"location":"95-reference/#AcceleratedDCTs.FFTWBasedIDCT1Plan","page":"Reference","title":"AcceleratedDCTs.FFTWBasedIDCT1Plan","text":"FFTWBasedIDCT1Plan\n\nIDCT-I Plan for CPU arrays using FFTW's native REDFT00 with scaling.\n\n\n\n\n\n","category":"type"},{"location":"95-reference/#AcceleratedDCTs.IDCT1Plan","page":"Reference","title":"AcceleratedDCTs.IDCT1Plan","text":"IDCT1Plan\n\nOptimized IDCT-I Plan for device-agnostic execution.\n\n\n\n\n\n","category":"type"},{"location":"95-reference/#AcceleratedDCTs.IDCTPlan","page":"Reference","title":"AcceleratedDCTs.IDCTPlan","text":"IDCTPlan\n\nOptimized IDCT Plan for device-agnostic execution.\n\n\n\n\n\n","category":"type"},{"location":"95-reference/#AcceleratedDCTs._compute_idct1_scale-Union{Tuple{N}, Tuple{NTuple{N, Int64}, Any}} where N","page":"Reference","title":"AcceleratedDCTs._compute_idct1_scale","text":"Compute the normalization scale for IDCT-I. For DCT-I, the inverse is DCT-I itself scaled by 1/âˆ(2*(Mi-1)) for each dimension.\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#AcceleratedDCTs.dct1d-Union{Tuple{AbstractVector{T}}, Tuple{T}} where T<:Real","page":"Reference","title":"AcceleratedDCTs.dct1d","text":"dct1d(x::AbstractVector{T}) where T<:Real\n\nCompute the 1D Discrete Cosine Transform (DCT-II) of a real vector.\n\nAlgorithm\n\nUses FFT-based computation:\n\nReorder input: v[n] = x[2n] for n < N/2, v[n] = x[2N-2n-1] for n >= N/2\nCompute FFT: V = fft(v)\nApply twiddle factors: y[k] = Re(V[k] * exp(-jÏ€k/(2N)))\n\nArguments\n\nx: Input vector of length N\n\nReturns\n\nDCT coefficients vector of length N\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#AcceleratedDCTs.dct2d-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T<:Real","page":"Reference","title":"AcceleratedDCTs.dct2d","text":"dct2d(x::AbstractMatrix{T}) where T<:Real\n\nCompute the 2D Discrete Cosine Transform (DCT-II) of a real matrix.\n\nAlgorithm\n\nUses separable 1D DCT transforms:\n\nApply 1D DCT to each row\nApply 1D DCT to each column\n\nArguments\n\nx: Input matrix of size MÃ—N\n\nReturns\n\nDCT coefficients matrix of size MÃ—N\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#AcceleratedDCTs.dct3d-Union{Tuple{AbstractArray{T, 3}}, Tuple{T}} where T<:Real","page":"Reference","title":"AcceleratedDCTs.dct3d","text":"dct3d(x::AbstractArray{T,3}) where T<:Real\n\nCompute the 3D Discrete Cosine Transform (DCT-II) of a real 3D array.\n\nAlgorithm\n\nUses separable 1D DCT transforms:\n\nApply 1D DCT along dimension 1 (rows)\nApply 1D DCT along dimension 2 (columns)\nApply 1D DCT along dimension 3 (depth)\n\nArguments\n\nx: Input array of size LÃ—MÃ—N\n\nReturns\n\nDCT coefficients array of size LÃ—MÃ—N\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#AcceleratedDCTs.dct_batched!-Union{Tuple{T}, Tuple{AbstractVector{T}, AbstractVector{T}, AcceleratedDCTs.DCTBatchedPlan{T, 1}}} where T","page":"Reference","title":"AcceleratedDCTs.dct_batched!","text":"dct_batched!(y, x, plan::DCTBatchedPlan)\n\nCompute the N-dimensional DCT of x and store the result in y. Uses preallocated buffers from the plan.\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#AcceleratedDCTs.idct1d-Union{Tuple{AbstractVector{T}}, Tuple{T}} where T<:Real","page":"Reference","title":"AcceleratedDCTs.idct1d","text":"idct1d(y::AbstractVector{T}) where T<:Real\n\nCompute the 1D Inverse Discrete Cosine Transform (IDCT, DCT-III) of DCT coefficients.\n\nAlgorithm\n\nUses FFT-based computation:\n\nReconstruct FFT coefficients V from DCT coefficients y\nApply inverse FFT: v = ifft(V)\nInverse reorder to get original signal\n\nArguments\n\ny: DCT coefficients vector of length N\n\nReturns\n\nReconstructed signal vector of length N\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#AcceleratedDCTs.idct2d-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T<:Real","page":"Reference","title":"AcceleratedDCTs.idct2d","text":"idct2d(y::AbstractMatrix{T}) where T<:Real\n\nCompute the 2D Inverse Discrete Cosine Transform (IDCT, DCT-III) of DCT coefficients.\n\nAlgorithm\n\nUses separable 1D IDCT transforms:\n\nApply 1D IDCT to each column\nApply 1D IDCT to each row\n\nArguments\n\ny: DCT coefficients matrix of size MÃ—N\n\nReturns\n\nReconstructed signal matrix of size MÃ—N\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#AcceleratedDCTs.idct3d-Union{Tuple{AbstractArray{T, 3}}, Tuple{T}} where T<:Real","page":"Reference","title":"AcceleratedDCTs.idct3d","text":"idct3d(y::AbstractArray{T,3}) where T<:Real\n\nCompute the 3D Inverse Discrete Cosine Transform (IDCT, DCT-III) of DCT coefficients.\n\nAlgorithm\n\nUses separable 1D IDCT transforms:\n\nApply 1D IDCT along dimension 3 (depth)\nApply 1D IDCT along dimension 2 (columns)\nApply 1D IDCT along dimension 1 (rows)\n\nArguments\n\ny: DCT coefficients array of size LÃ—MÃ—N\n\nReturns\n\nReconstructed signal array of size LÃ—MÃ—N\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#AcceleratedDCTs.idct_batched!-Union{Tuple{T}, Tuple{AbstractVector{T}, AbstractVector{T}, AcceleratedDCTs.DCTBatchedPlan{T, 1}}} where T","page":"Reference","title":"AcceleratedDCTs.idct_batched!","text":"idct_batched!(x, y, plan::DCTBatchedPlan)\n\nCompute the N-dimensional IDCT of y and store the result in x. Uses preallocated buffers from the plan.\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#AcceleratedDCTs.idct_postprocess_batch_dim1_kernel!-Tuple{Any}","page":"Reference","title":"AcceleratedDCTs.idct_postprocess_batch_dim1_kernel!","text":"IDCT Postprocess batch (inverse reorder). v: (N, Batch), x: (N, Batch)\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#AcceleratedDCTs.idct_preprocess_batch_dim1_kernel!-Tuple{Any}","page":"Reference","title":"AcceleratedDCTs.idct_preprocess_batch_dim1_kernel!","text":"IDCT Preprocess batch with precomputed twiddles. y: (N, Batch) real, V: (halfN+1, Batch) complex twiddles_inv: (halfN+1,) complex (cispi(k/(2N)))\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#AcceleratedDCTs.permutedims_2d!-Union{Tuple{T}, Tuple{AbstractMatrix{T}, AbstractMatrix{T}}} where T","page":"Reference","title":"AcceleratedDCTs.permutedims_2d!","text":"permutedims_2d!(dst, src)\n\nIn-place 2D transpose using KernelAbstractions.\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#AcceleratedDCTs.permutedims_2d_kernel!-Tuple{Any}","page":"Reference","title":"AcceleratedDCTs.permutedims_2d_kernel!","text":"2D permutedims! kernel\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#AcceleratedDCTs.permutedims_3d!-Union{Tuple{T}, Tuple{AbstractArray{T, 3}, AbstractArray{T, 3}, Tuple{Int64, Int64, Int64}}} where T","page":"Reference","title":"AcceleratedDCTs.permutedims_3d!","text":"permutedims_3d!(dst, src, perm)\n\nIn-place 3D permutedims using KernelAbstractions.  Zero allocation after initial kernel compilation.\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#AcceleratedDCTs.permutedims_3d_kernel!-Tuple{Any}","page":"Reference","title":"AcceleratedDCTs.permutedims_3d_kernel!","text":"3D permutedims! kernel: dst[i,j,k] = src[perm_inverse...] perm specifies the output dimension order from input dimensions.\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#AcceleratedDCTs.plan_dct_batched-Union{Tuple{AbstractArray{T, N}}, Tuple{N}, Tuple{T}} where {T<:Real, N}","page":"Reference","title":"AcceleratedDCTs.plan_dct_batched","text":"plan_dct_batched(x::AbstractArray{T, N}) where {T <: Real, N}\n\nCreate a batched DCT plan for arrays with the same size and element type as x.\n\nExample\n\nx = rand(256, 256, 256)\nplan = plan_dct_batched(x)\ny = plan * x   # DCT\nmul!(y, plan, x)  # DCT (zero allocation)\nx2 = plan \\ y  # IDCT\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#AcceleratedDCTs.postprocess_batch_dim1_kernel!-Tuple{Any}","page":"Reference","title":"AcceleratedDCTs.postprocess_batch_dim1_kernel!","text":"Postprocess batch of 1D signals with precomputed twiddles. V: (halfN+1, Batch) complex, y: (N, Batch) real twiddles: (N,) complex\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#AcceleratedDCTs.preprocess_batch_dim1_kernel!-Tuple{Any}","page":"Reference","title":"AcceleratedDCTs.preprocess_batch_dim1_kernel!","text":"Preprocess batch of 1D signals along first dimension. x: (N, Batch), v: (N, Batch)\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#Base.:*-Union{Tuple{T}, Tuple{AcceleratedDCTs.DCTBatchedPlan{T, 1}, AbstractVector{T}}} where T","page":"Reference","title":"Base.:*","text":"Base.:*(plan::DCTBatchedPlan, x::AbstractArray) -> y\n\nCompute the N-dimensional DCT of x using the precomputed plan.\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#Base.:\\-Union{Tuple{T}, Tuple{AcceleratedDCTs.DCTBatchedPlan{T, 1}, AbstractVector{T}}} where T","page":"Reference","title":"Base.:\\","text":"Base.:\\(plan::DCTBatchedPlan, y::AbstractArray) -> x\n\nCompute the N-dimensional IDCT of y using the precomputed plan.\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#LinearAlgebra.ldiv!-Union{Tuple{T}, Tuple{AbstractArray{T, 3}, AcceleratedDCTs.DCTBatchedPlan{T, 3}, AbstractArray{T, 3}}} where T","page":"Reference","title":"LinearAlgebra.ldiv!","text":"LinearAlgebra.ldiv!(x, plan::DCTBatchedPlan{T, 3}, y) -> x\n\nCompute 3D IDCT with zero allocation using ping-pong buffer strategy.\n\nFlow (reverse of DCT):\n\ny    â†’ perm(3,1,2) â†’ buf  # buf = (3',1',2')\nbuf  â†’ IDCT dim1 â†’ x     # x   = (3,1',2')\nx    â†’ perm(3,2,1) â†’ buf  # buf = (2',1',3)\nbuf  â†’ IDCT dim1 â†’ x     # x   = (2,1',3)\nx    â†’ perm(2,1,3) â†’ buf  # buf = (1',2,3)\nbuf  â†’ IDCT dim1 â†’ x     # x   = (1,2,3) âœ“\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#LinearAlgebra.mul!-Union{Tuple{T}, Tuple{AbstractArray{T, 3}, AcceleratedDCTs.DCTBatchedPlan{T, 3}, AbstractArray{T, 3}}} where T","page":"Reference","title":"LinearAlgebra.mul!","text":"LinearAlgebra.mul!(y, plan::DCTBatchedPlan{T, 3}, x) -> y\n\nCompute 3D DCT with zero allocation using ping-pong buffer strategy. Uses y and plan.temp_buffer alternately to avoid allocations.\n\nFlow (ping-pong between buf and y):\n\nx    â†’ DCT dim1 â†’ buf     # buf = (1',2,3)\nbuf  â†’ perm(2,1,3) â†’ y    # y   = (2,1',3)\ny    â†’ DCT dim1 â†’ buf     # buf = (2',1',3)\nbuf  â†’ perm(3,2,1) â†’ y    # y   = (3,2',1')\ny    â†’ DCT dim1 â†’ buf     # buf = (3',2',1')\nbuf  â†’ perm(2,3,1) â†’ y    # y   = (1',2',3') âœ“\n\n\n\n\n\n","category":"method"},{"location":"30-implementation/#Implementation-Details","page":"Implementation","title":"Implementation Details","text":"","category":"section"},{"location":"30-implementation/#KernelAbstractions.jl","page":"Implementation","title":"KernelAbstractions.jl","text":"The code is written using KernelAbstractions, meaning the exact same code runs on:\n\nCPU (using Base.Threads)\nNVIDIA GPU (using CUDA.jl)\nAMD GPU (using AMDGPU.jl) - conceptual support, untested\n\nWe strictly avoid \"scalar indexing\" (accessing single elements from the host), ensuring high performance on GPUs.","category":"section"},{"location":"30-implementation/#Plan-Based-API-(AbstractFFTs)","page":"Implementation","title":"Plan-Based API (AbstractFFTs)","text":"To maximize performance, we separate resource allocation (cheap on CPU, expensive on GPU) from execution.","category":"section"},{"location":"30-implementation/#DCT-II/DCT-III-Plans","page":"Implementation","title":"DCT-II/DCT-III Plans","text":"plan_dct(x) / plan_idct(x):\nAllocates temporary buffers (tmp_real, tmp_comp).\nCreates an internal FFT plan (plan_rfft).\nPre-calculates twiddle factors (cispi(...)) on the device.","category":"section"},{"location":"30-implementation/#DCT-I-Plans","page":"Implementation","title":"DCT-I Plans","text":"plan_dct1(x) / plan_idct1(x):\nCPU (Array): Uses FFTW's native REDFT00 for optimal performance.\nGPU (CuArray): Uses mirroring buffer (size 2M-2) + R2C FFT.\nDispatch is automatic based on array type.","category":"section"},{"location":"30-implementation/#Execution","page":"Implementation","title":"Execution","text":"mul!(y, p, x):\nReuses all buffers.\nZero memory allocation during execution.","category":"section"},{"location":"25-normalization/#Normalization-and-Conventions","page":"Normalization","title":"Normalization & Conventions","text":"This page clarifies the normalization conventions used in AcceleratedDCTs.jl compared to FFTW.jl. This is a common source of confusion, as AcceleratedDCTs.jl (following Makhoul's algorithm) uses a non-unitary definition, while FFTW.dct (and generally AbstractFFTs ecosystem) defaults to an orthogonal (unitary) definition (DCT-II).","category":"section"},{"location":"25-normalization/#Definitions-Used-in-AcceleratedDCTs.jl","page":"Normalization","title":"Definitions Used in AcceleratedDCTs.jl","text":"We implement the standard \"pure sum\" definition for the Forward transform (DCT-II) and the matching Inverse transform (DCT-III):\n\nForward Transform (DCT-II)\n\nX_k = sum_n=0^N-1 x_n cosleft(fracpiNleft(n+frac12right)kright)\n\nInverse Transform (DCT-III)\n\nx_n = frac12X_0 + sum_k=1^N-1 X_k cosleft(fracpiNnleft(k+frac12right)right)\n\nIn this package's high-level API (dct, idct), we ensure idct(dct(x)) â‰ˆ x. The necessary inverse scaling factors are handled internally by the inverse transform.","category":"section"},{"location":"25-normalization/#Summary-of-Differences","page":"Normalization","title":"Summary of Differences","text":"Feature AcceleratedDCTs.jl (Makhoul) FFTW.jl (Standard DCT-II)\nMathematical Type Non-unitary DCT-II Orthogonal (Unitary) DCT-II\nScaling (Roundtrip) 2^d cdot N 2^d cdot N *\nForward Transform Unscaled sum Scaled by normalization factors\nInverse Transform Scaled by 2N implicitly Scaled by normalization factors\n\n* Note: FFTW's unnormalized plans also involve scaling, but FFTW.dct usually implies the unitary one unless specified.","category":"section"},{"location":"25-normalization/#Detailed-Normalization-Coefficients","page":"Normalization","title":"Detailed Normalization Coefficients","text":"Here we compare the normalization coefficient C applied to each element in the Forward transform. The coefficient depends on the frequency index k in each dimension.\n\n$\n\ny = C(k) \\cdot \\text{DCT}_{\\text{sum}}(x) $\n\nFor FFTW.jl (Orthogonal), the rule is simple: Any dimension with index k=0 contributes a factor of sqrt1N, while any dimension with index k0 contributes sqrt2N.\n\nDimension Type of Index (k) AcceleratedDCTs.jl FFTW.jl (Orthogonal)\n1D k=0 (DC) 1 sqrt1N\n k0 (AC) 1 sqrt2N\n2D (00) 1 frac1sqrtN_1 N_2\n (0 k) with k0 1 frac1sqrtN_1 sqrtfrac2N_2\n (k 0) with k0 1 sqrtfrac2N_1 frac1sqrtN_2\n (k l) where kl0 1 frac2sqrtN_1 N_2\n3D (000) 1 frac1sqrtN_1 N_2 N_3\n (00k) (k0) 1 frac1sqrtN_1 N_2 sqrtfrac2N_3\n (0kl) (kl0) 1 frac1sqrtN_1 frac2sqrtN_2 N_3\n (klm) (klm  0) 1 frac2sqrt2sqrtN_1 N_2 N_3","category":"section"},{"location":"25-normalization/#Conclusion","page":"Normalization","title":"Conclusion","text":"AcceleratedDCTs.jl does NOT apply these position-dependent normalization factors during the forward transform. It computes the raw cosine sums.\n\nIf you need to match FFTW's output exactly (e.g. for comparison), you must manually apply these scaling factors to the output of AcceleratedDCTs.dct.","category":"section"},{"location":"#AcceleratedDCTs.jl","page":"AcceleratedDCTs.jl","title":"AcceleratedDCTs.jl","text":"Documentation for AcceleratedDCTs.","category":"section"},{"location":"#Introduction","page":"AcceleratedDCTs.jl","title":"Introduction","text":"AcceleratedDCTs.jl aims to provide the fastest possible Discrete Cosine Transform (DCT) for Julia, running on both CPUs and GPUs. It supports:\n\nDCT-II (Standard \"DCT\") and DCT-III (Inverse DCT) â€” commonly used in signal processing and solving PDEs\nDCT-I and IDCT-I â€” for symmetric boundary conditions\n\nThe core innovation of this package is the implementation of Algorithm 2 (2D) and Algorithm 3 (3D), which reduce N-dimensional DCTs to N-dimensional Real-to-Complex (R2C) FFTs with O(N) pre/post-processing steps, avoiding the overhead of separable 1D transforms (which require redundant transposes).","category":"section"},{"location":"#Key-Features","page":"AcceleratedDCTs.jl","title":"Key Features","text":"âš¡ High Performance: optimized algorithms (Makhoul's method) that outperform standard separable approaches on GPU (~2x speedup for 3D) and CPU (~3x speedup for 3D).\nðŸš€ Device Agnostic: Runs on CPU (Threads) and GPU (CuArray, ROCArray via KernelAbstractions).\nðŸ§© AbstractFFTs Compatible: Zero-allocation mul!, ldiv!, and precomputed Plan support.\nðŸ“¦ 3D Optimized: Specialized 3D kernels that avoid redundant transposes.","category":"section"}]
}
